{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things need to explore & try:\n",
    "- VectorStore\n",
    "- Chain together\n",
    "- Memory\n",
    "- Streamlit combine\n",
    "- Agent graphs\n",
    "- Call tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain_community.vectorstores import FAISS \n",
    "from langchain.memory import ConversationBufferMemory, ChatMessageHistory\n",
    "from langchain.chains import ConversationalRetrievalChain, create_retrieval_chain\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain import hub\n",
    "from htmlTemplate import css, bot_template, user_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\"\n",
    "About Us: We are a Global Group AI team that empowers organization with citizen data scientists and enforces governance to ensure responsible and ethical use of AI. Our team is responsible for developing advanced analytics and machine learning models, and delivering data-driven insights to business leaders across the organization.\n",
    "Job Description: As a Junior Data Scientist, you will be responsible for creating and implementing complex machine learning models, performing data analysis, and driving insights from large datasets. You will work with stakeholders across the organization to understand their business needs and translate them into data-driven solutions. You will also work closely with citizen data scientists to help them leverage data and build models for their business problems.\n",
    "Key Responsibilities:\n",
    "• Develop and implement machine learning models to solve complex business problems, using techniques such as linear regression, logistic regression, decision trees, and other supervised and unsupervised learning models.\n",
    "• Perform data analysis and create insights from large datasets.\n",
    "• Work with stakeholders across the organization to understand business needs and translate\n",
    "them into data-driven solutions.\n",
    "• Collaborate with citizen data scientists to empower them to leverage data and build models\n",
    "for their business problems.\n",
    "• Enforce governance to ensure responsible and ethical use of data.\n",
    "• Keep up-to-date with the latest developments in machine learning and data science.\n",
    "Requirements:\n",
    "• Bachelor's or Master's degree in Computer Science, Statistics, Mathematics, Actuarial Science or related fields.\n",
    "• At least 1-4 years of experience in data science or related field.\n",
    "• Strong knowledge of machine learning algorithms and statistical modelling techniques,\n",
    "especially using Scikit-learn.\n",
    "• Proficiency in Python, PySpark and SQL.\n",
    "• Experience with data visualization and reporting tools (e.g. Power BI, QlikSense).\n",
    "• Excellent communication and problem-solving skills.\n",
    "• Experience with GenAI solutions and prompt engineering\n",
    "Nice-to-haves:\n",
    "• Familiarity with actuarial methods and models.\n",
    "• Experience in MLOps and data pipelines eg, Bitbucket, Artifactory, Jenkins\n",
    "• Familiarity with deep learning frameworks (e.g. TensorFlow, PyTorch).\n",
    "• Experience with cloud-based services (e.g. AWS, Azure, GCP).\n",
    "• Knowledge of big data technologies (e.g. Hadoop, Spark).\n",
    "If you're interested in this position, please send your resume and cover letter to [Global Group AI team email address]. We look forward to hearing from you!\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. TextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size = 800,\n",
    "        chunk_overlap = 200,\n",
    "        length_function = len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "text_chunks = get_text_chunks(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Embedding to VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorestore(text_chunks):\n",
    "    embeddings = OpenAIEmbeddings(base_url=\"https://api.bianxie.ai/v1\")\n",
    "    #embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\")\n",
    "    vectorsore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
    "    return vectorsore\n",
    "\n",
    "vectorstore = get_vectorestore(text_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Define LLM & Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(base_url = \"https://api.bianxie.ai/v1\")\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The PDF is about a Global Group AI team that empowers organizations with citizen data scientists and enforces governance to ensure responsible and ethical use of AI.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"What is this pdf about? Answer me with one sentence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e. Chain with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do not answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\n",
    "\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "    Use the following pieces of retrived context to answer the question. \\\n",
    "    If you don't know the answer, just say you don't know. \\\n",
    "    Use three sentences maximum and keep the answer concise. \\\n",
    "    \n",
    "    {context}\n",
    "\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text is a job description for a Junior Data Scientist position within a Global Group AI team that focuses on developing and implementing advanced analytics and machine learning models to deliver data-driven insights to business leaders.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\"\n",
    ")\n",
    "\n",
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What is this text about? Answer me with one sentence\"},\n",
    "    config = {\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the job description, the most important quality to have for this Junior Data Scientist position is a strong knowledge of machine learning algorithms and statistical modeling techniques, especially using Scikit-learn.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What's the most important quality to get this job according to the JD?\"},\n",
    "    config = {\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Another important quality for this Junior Data Scientist position is proficiency in programming languages like Python, PySpark, and SQL, as well as experience with data visualization and reporting tools such as Power BI and QlikSense.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What else?\"},\n",
    "    config = {\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc123': InMemoryChatMessageHistory(messages=[HumanMessage(content='What is this text about? Answer me with one sentence', additional_kwargs={}, response_metadata={}), AIMessage(content='The text is a job description for a Junior Data Scientist position within a Global Group AI team that focuses on developing and implementing advanced analytics and machine learning models to deliver data-driven insights to business leaders.', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"What's the most important quality to get this job according to the JD?\", additional_kwargs={}, response_metadata={}), AIMessage(content='According to the job description, the most important quality to have for this Junior Data Scientist position is a strong knowledge of machine learning algorithms and statistical modeling techniques, especially using Scikit-learn.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What else?', additional_kwargs={}, response_metadata={}), AIMessage(content='Another important quality for this Junior Data Scientist position is proficiency in programming languages like Python, PySpark, and SQL, as well as experience with data visualization and reporting tools such as Power BI and QlikSense.', additional_kwargs={}, response_metadata={})])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_pdfchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
